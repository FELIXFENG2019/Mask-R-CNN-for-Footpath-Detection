{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Dataset download and preprocessing.ipynb","provenance":[],"collapsed_sections":["yRD1Py_4JiAt"],"machine_shape":"hm","mount_file_id":"1ut9wbd5DtmgxyDS0qTVKfWBEj0C_bnG5","authorship_tag":"ABX9TyO2vIcBZlOVyOoIev0Gzy/f"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"DxkpiyhqYbLw","colab_type":"text"},"source":["## Configuration Script"]},{"cell_type":"code","metadata":{"id":"w1VR3fSy6-3M","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1595936010803,"user_tz":-60,"elapsed":524,"user":{"displayName":"SHIJIA FENG","photoUrl":"","userId":"04645087319027364305"}},"outputId":"fe0d115b-f2ca-4e32-a6b6-bf3ea7a5e68b"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9WOKZLC87cRy","colab_type":"code","colab":{}},"source":["# 安装最新版本Keras\n","# https://keras.io/\n","#!pip install keras\n","#最新版 keras==2.3.0 2020.06.27\n","# 指定版本安装\n","#!pip install keras==2.0.8\n","!pip install keras==2.1.5\n","\n","%tensorflow_version 1.x\n","!pip install imgaug==0.2.5\n","!pip install gast==0.2.2\n","\n","# 安装 OpenCV\n","# https://opencv.org/\n","!apt-get -qq install -y libsm6 libxext6 && pip install -q -U opencv-python\n","# 安装 Pytorch\n","# http://pytorch.org/\n","!pip install --upgrade pip\n","!pip install folium==0.2.1\n","!pip install numpy --upgrade\n","!pip install torch==1.5.1\n","# 安装 XGBoost\n","# https://github.com/dmlc/xgboost\n","!pip install -q xgboost\n","# 安装 7Zip\n","!apt-get -qq install -y libarchive-dev && pip install -q -U libarchive\n","# 安装 GraphViz 和 PyDot\n","!apt-get -qq install -y graphviz && pip install -q pydot\n","\n","#import tensorflow\n","#print(tensorflow.__version__)\n","\n","!pip install --upgrade pip\n","!pip install folium==0.2.1\n","!pip install numpy --upgrade\n","!pip install torch==1.5.1\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yRD1Py_4JiAt","colab_type":"text"},"source":["## Download DIODE Dataset and unzip "]},{"cell_type":"code","metadata":{"id":"4BOlTs5K7yZR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1595872047144,"user_tz":-60,"elapsed":2451,"user":{"displayName":"SHIJIA FENG","photoUrl":"","userId":"04645087319027364305"}},"outputId":"5c7fbc7e-bfc0-4ab0-9569-a23e7289827c"},"source":["import os\n","path = \"/content/drive/My Drive/Colab Notebooks/DIODE Depth\"\n","os.chdir(path)\n","\n","!ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["val  val.tar.gz\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pbnq5nc_8dAW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":215},"executionInfo":{"status":"ok","timestamp":1595881548396,"user_tz":-60,"elapsed":9413038,"user":{"displayName":"SHIJIA FENG","photoUrl":"","userId":"04645087319027364305"}},"outputId":"a62bcaf9-53df-40f6-92af-1c76dfadd2d2"},"source":["import os\n","path = \"/content/drive/My Drive/Colab Notebooks/DIODE Depth\"\n","os.chdir(path)\n","\n","!wget http://diode-dataset.s3.amazonaws.com/train.tar.gz\n","\n","import shutil\n","shutil.unpack_archive(\"train.tar.gz\", path)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2020-07-27 17:48:20--  http://diode-dataset.s3.amazonaws.com/train.tar.gz\n","Resolving diode-dataset.s3.amazonaws.com (diode-dataset.s3.amazonaws.com)... 52.216.144.115\n","Connecting to diode-dataset.s3.amazonaws.com (diode-dataset.s3.amazonaws.com)|52.216.144.115|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 86747209190 (81G) [application/x-tar]\n","Saving to: ‘train.tar.gz’\n","\n","train.tar.gz        100%[===================>]  80.79G  30.8MB/s    in 49m 36s \n","\n","2020-07-27 18:37:57 (27.8 MB/s) - ‘train.tar.gz’ saved [86747209190/86747209190]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yllwTsOO_2ww","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":215},"executionInfo":{"status":"ok","timestamp":1595719108376,"user_tz":-60,"elapsed":198180,"user":{"displayName":"SHIJIA FENG","photoUrl":"","userId":"04645087319027364305"}},"outputId":"f5b3e2b0-3115-411b-abf0-ba37b5eac77e"},"source":["!wget http://diode-dataset.s3.amazonaws.com/val.tar.gz"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2020-07-25 23:14:35--  http://diode-dataset.s3.amazonaws.com/val.tar.gz\n","Resolving diode-dataset.s3.amazonaws.com (diode-dataset.s3.amazonaws.com)... 52.217.84.84\n","Connecting to diode-dataset.s3.amazonaws.com (diode-dataset.s3.amazonaws.com)|52.217.84.84|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2774625282 (2.6G) [application/x-tar]\n","Saving to: ‘val.tar.gz’\n","\n","val.tar.gz          100%[===================>]   2.58G  14.2MB/s    in 3m 15s  \n","\n","2020-07-25 23:17:51 (13.6 MB/s) - ‘val.tar.gz’ saved [2774625282/2774625282]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"t7k3PtUR9EAK","colab_type":"code","colab":{}},"source":["# !find / -name train.tar.gz\n","import shutil\n","import os\n","path = \"/content/drive/My Drive/Colab Notebooks/DIODE Depth\"\n","os.chdir(path)\n","# shutil.unpack_archive(\"val.tar.gz\", \"/content/drive/My Drive/Colab Notebooks/DIODE Depth\")\n","#shutil.unpack_archive(\"train.tar.gz\", path)\n","!tar -zxvf train.tar.gz"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sEu5-jLSdTx6","colab_type":"code","colab":{}},"source":["import os\n","import shutil\n","path = \"/content/drive/My Drive/Colab Notebooks/DIODE Depth/train/indoors\"\n","os.chdir(path)\n","\n","#!unzip scene_00001.zip\n","!jar xvf scene_00001.zip"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9d0Bpk8EJwyG","colab_type":"text"},"source":["## Calculate mean pixel value (original depth data)"]},{"cell_type":"code","metadata":{"id":"tQV5adbUJv0X","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1595969046020,"user_tz":-60,"elapsed":32722324,"user":{"displayName":"SHIJIA FENG","photoUrl":"","userId":"04645087319027364305"}},"outputId":"e1a327a3-ed09-4a00-d971-8e21a757e958"},"source":["import os\n","import numpy as np\n","import fnmatch\n","\n","basepath = \"/content/drive/My Drive/Colab Notebooks/DIODE Depth\"\n","depth_means = []\n","subsets = ['train', 'val']\n","occasions = ['indoors', 'outdoor']\n","for subset in subsets:\n","  level1_dir = os.path.join(basepath, subset)\n","  for occasion in occasions:\n","    level2_dir = os.path.join(level1_dir, occasion)\n","    scenes = os.listdir(level2_dir)\n","    for scene in scenes:\n","      level3_dir = os.path.join(level2_dir, scene)\n","      scans = os.listdir(level3_dir)\n","      for scan in scans:\n","        data_dir = os.path.join(level3_dir, scan)\n","        image_files = os.listdir(data_dir)\n","        depth_images = [image_file for image_file in image_files if fnmatch.fnmatch(image_file, '*_depth.npy')]\n","        for depth_image in depth_images:\n","          temp_dir = os.path.join(data_dir, depth_image)\n","          depth_imarr = np.load(temp_dir)\n","          im_depth = depth_imarr[:, :, 0]\n","          im_depth_mean = np.mean(im_depth)\n","          depth_means.append(im_depth_mean)\n","all_images_depth_mean = np.mean(depth_means)\n","all_images_depth_std = np.std(depth_means)\n","\n","print('mean: ', all_images_depth_mean)\n","print('std: ', all_images_depth_std)\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["mean:  7.172033\n","std:  6.0548925\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ozSt1d3vUkji","colab_type":"text"},"source":["## Calculate mean pixel value (depth visualization)"]},{"cell_type":"code","metadata":{"id":"t6Y-_vIYUjzE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":143},"executionInfo":{"status":"ok","timestamp":1596486197753,"user_tz":-60,"elapsed":198016,"user":{"displayName":"SHIJIA FENG","photoUrl":"","userId":"04645087319027364305"}},"outputId":"3433ce5d-f4c8-49b0-df1a-59600b374c29"},"source":["import os\n","import numpy as np\n","import fnmatch\n","import cv2\n","import time\n","from tqdm import tqdm\n","\n","\n","basepath = \"/content/drive/My Drive/Colab Notebooks/DIODE Dataset Backup\"\n","val_library_path = os.path.join(basepath, 'val images list.txt')\n","train_library_path = os.path.join(basepath, 'train images list.txt')\n","r_means = []\n","g_means = []\n","b_means = []\n","images = []\n","\n","subsets = ['val', 'train']\n","for subset in subsets:\n","  level1_dir = os.path.join(basepath, subset)\n","  if subset == 'train':\n","    print(\"Begin calculating means and std in train folder \")\n","    with open(train_library_path, mode='r') as file_object:\n","      contents = file_object.readlines()\n","      for image_name in contents:\n","        image_name = image_name.strip('\\n')\n","        if image_name:\n","          images.append(image_name.replace('.png', '_depth_visualization.png'))\n","  elif subset == 'val':\n","    print(\"Begin calculating means and std in val folder \")\n","    with open(val_library_path, mode='r') as file_object:\n","      contents = file_object.readlines()\n","      for image_name in contents:\n","        image_name = image_name.strip('\\n')\n","        if image_name:\n","          images.append(image_name.replace('.png', '_depth_visualization.png'))\n","  \n","  with tqdm(total=len(images), desc=subset, leave=True, unit='img', unit_scale=True) as pbar:\n","    for image in images:\n","      img_path = os.path.join(level1_dir, image)\n","      image_arr = cv2.imread(img_path)\n","      if image_arr is None:\n","        print(\"cv returns nothing on the given image path\")\n","        print(img_path)\n","        print(image)\n","      image_arr_b = image_arr[:, :, 0]\n","      image_arr_g = image_arr[:, :, 1]\n","      image_arr_r = image_arr[:, :, 2]\n","      per_img_b_mean = np.mean(image_arr_b)\n","      per_img_g_mean = np.mean(image_arr_g)\n","      per_img_r_mean = np.mean(image_arr_r)\n","      b_means.append(per_img_b_mean)\n","      g_means.append(per_img_g_mean)\n","      r_means.append(per_img_r_mean)\n","\n","      pbar.update(1)\n","  \n","  images = []\n","\n","B_mean = np.mean(b_means)\n","G_mean = np.mean(g_means)\n","R_mean = np.mean(r_means)\n","\n","B_std = np.std(b_means)\n","G_std = np.std(g_means)\n","R_std = np.std(r_means)\n","\n","print(\"Calculation completed!\")\n","\n","print('R mean= ', R_mean, 'G mean= ', G_mean, 'B mean= ', B_mean)\n","print('R std= ', R_std, 'G std= ', G_std, 'B std= ', B_std)\n","\n"],"execution_count":11,"outputs":[{"output_type":"stream","text":["val:   1%|          | 6.00/771 [00:00<00:14, 52.9img/s]"],"name":"stderr"},{"output_type":"stream","text":["Begin calculating means and std in val folder \n"],"name":"stdout"},{"output_type":"stream","text":["val: 100%|██████████| 771/771 [00:15<00:00, 51.2img/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Begin calculating means and std in train folder \n"],"name":"stdout"},{"output_type":"stream","text":["train: 100%|██████████| 4.43k/4.43k [03:01<00:00, 24.4img/s]"],"name":"stderr"},{"output_type":"stream","text":["Calculation completed!\n","R mean=  95.15703400213121 G mean=  111.07604387210047 B mean=  39.98726765599171\n","R std=  87.05336227331514 G std=  86.08837985779063 B std=  46.022403445410724\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"0tTAOVv5lS-9","colab_type":"text"},"source":["## DIODE Dataset files movement"]},{"cell_type":"code","metadata":{"id":"jbJ-NMqnlR3l","colab_type":"code","colab":{}},"source":["import os\n","import numpy as np\n","import shutil\n","\n","basepath = \"/content/drive/My Drive/Colab Notebooks/DIODE Depth\"\n","train_dir = \"/content/drive/My Drive/Colab Notebooks/DIODE Dataset/train\"\n","val_dir = \"/content/drive/My Drive/Colab Notebooks/DIODE Dataset/val\"\n","depth_means = []\n","subsets = ['train', 'val']\n","occasions = ['indoors', 'outdoor']\n","for subset in subsets:\n","  if subset == 'train':\n","    destination_dir = train_dir\n","  elif subset == 'val':\n","    destination_dir = val_dir\n","  level1_dir = os.path.join(basepath, subset)\n","  for occasion in occasions:\n","    level2_dir = os.path.join(level1_dir, occasion)\n","    scenes = os.listdir(level2_dir)\n","    for scene in scenes:\n","      level3_dir = os.path.join(level2_dir, scene)\n","      scans = os.listdir(level3_dir)\n","      for scan in scans:\n","        data_dir = os.path.join(level3_dir, scan)\n","        image_files = os.listdir(data_dir)\n","        selected_images = [image_file for image_file in image_files if not image_file.endswith('.txt')]\n","        for selected_image in selected_images:\n","          temp_dir = os.path.join(data_dir, selected_image)\n","          shutil.copy(temp_dir, destination_dir)\n","        print('Finished moving the files in {} / {} into the destination directory'.format(scan, scene))\n","\n","print(\"Successfully moving all the files in the dataset!\")\n"],"execution_count":null,"outputs":[]}]}